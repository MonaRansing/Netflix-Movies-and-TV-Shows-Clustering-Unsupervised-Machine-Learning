{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "35m5QtbWiB9F",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonaRansing/Netflix-Movies-and-TV-Shows-Clustering-Unsupervised-Machine-Learning/blob/main/Netflix_Movies_and_TV_Shows_Clustering_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Netflix Movies and TV Shows Clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to analyze the evolution of Netflix's content library, using a dataset of TV shows and movies available on Netflix as of 2019, collected from Flixable. Since 2010, the number of TV shows on Netflix has nearly tripled, while the number of movies has decreased by over 2,000 titles. Through Exploratory Data Analysis (EDA), visualization, data cleaning, and unsupervised machine learning algorith, the project will uncover trends in content availability, genre distribution, and other key attributes. Integrating this dataset with external sources such as IMDb and Rotten Tomatoes will enrich the analysis, providing insights into content popularity and quality. The project will also employ clustering algorithms to identify content similarities and use dimensionality reduction techniques to reveal hidden patterns. The outcome will be detailed insights into Netflix's content strategy, interactive dashboards for user exploration, and a comprehensive view of how Netflix content is perceived in the broader entertainment ecosystem."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine. In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.\n",
        "\n",
        "In this project, you are required to do\n",
        "\n",
        "* Exploratory Data Analysis\n",
        "* Understanding what type content is available in different countries\n",
        "* If Netflix has been increasingly focusing on TV rather than movies in recent years.\n",
        "* Clustering similar content by matching text-based features"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as mtick\n",
        "from matplotlib.pyplot import figure\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Almabetter/Data Science/dataset/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "0kzg9By0JUIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "vj_U7izpKJTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy main dataset\n",
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "xRXKkv3YMVpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "zWK7YvEKKXH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_values = df1.duplicated().sum()\n",
        "duplicate_values"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#null values\n",
        "df1.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "oiLFY0Bwf62f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_value = df1.isnull().sum().sort_values(ascending=False).reset_index().rename(columns={'index':'Columns',0:'Missing Values'})\n",
        "missing_value.head(5)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "# Define a color palette\n",
        "palette = sns.color_palette(\"colorblind\", len(missing_value))\n",
        "\n",
        "# Create a bar plot with missing values\n",
        "plt.figure(figsize=(8,6))\n",
        "# Assuming 'missing_value' is a DataFrame with 'Columns' and 'Missing Values' columns\n",
        "ax = sns.barplot(x='Columns', y='Missing Values', data=missing_value.head(5), palette=palette)\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Missing Values')\n",
        "plt.title('Missing Values')\n",
        "\n",
        "# Adding the exact values on top of the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='baseline', fontsize=11, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the given dataset there are 7787 rows and 12 columns. There is duplicate values in the dataset.\n",
        "\n",
        "There are total 3631 missing values and 2389 missing values in director column, 718 missing vlaues in cast column, 507 missing values in country column, 10 missing values in data_added column, and 7 missing value in rating column."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df1.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "* type : Identifier - A Movie or TV Show\n",
        "\n",
        "* title : Title of the Movie / Tv Show\n",
        "\n",
        "* director : Director of the Movie\n",
        "\n",
        "* cast : Actors involved in the movie / show\n",
        "\n",
        "* country : Country where the movie / show was produced\n",
        "\n",
        "* date_added : Date it was added on Netflix\n",
        "\n",
        "* release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "* rating : TV Rating of the movie / show\n",
        "\n",
        "* duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "* listed_in : Genere\n",
        "\n",
        "* description: The Summary description"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df1.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "duplicate_values = df1.duplicated().sum()\n",
        "duplicate_values"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find out missing values\n",
        "missing_values = df1.isnull().sum().sort_values(ascending=False).reset_index().rename(columns={'index':'Columns',0:'Missing Values'})\n",
        "missing_values.head(5)"
      ],
      "metadata": {
        "id": "YSLy0f26_gqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace null values\n",
        "df1['cast'].fillna(value = \"No Cast\", inplace=True)\n",
        "df1['country'].fillna(value = df['country'].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "id": "y1htXe3A_vOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# date_added and ratings columns have some rows which have null values. so we drom them using dropna.\n",
        "df1.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "1gs6jEfSM8eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# director column is not needed so we drop that columns from dataset\n",
        "df1.drop(['director'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "I4wMst-ANlhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null values\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "XRoEIOmcBJ8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In the given dataset there is no duplicate values therefore no need to do any changes.\n",
        "\n",
        "* In the given dataset there are total 3613 missing values.\n",
        "* There are 5 columns which have missing values as follows:\n",
        "  * director - 2389\n",
        "  * cast - 718\n",
        " * country - 507\n",
        "  * date_added - 10\n",
        "  * rating - 7\n",
        "* From the above 5 columns I deropped 1 column which is director column because I do not neede for analysis and date_added and ratings columns have null values so I dropped those null values using dropna fumction.\n",
        "\n",
        "* Missing values from cast column is replace by \"No Cast\" and missing value from country column is replaced by name of countries from dataset."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **How many TV shows and movies are there in the dataset?**"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "lDuRfH_LEhTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate tv shows and movies\n",
        "tv_movie_shows = df1['type'].value_counts()\n",
        "tv_movie_shows"
      ],
      "metadata": {
        "id": "Jx-UY1PUEKTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization tv shows and movies\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(tv_movie_shows, labels=tv_movie_shows.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('TV Shows and Movies')\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked pie chart becuase it gives clear and simple visualization."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above pie chart we can see that there are more number of movies than TV shows."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **What is the distribution of release years for the content?**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "PX30V-KTY35w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate distribution of release years for the content\n",
        "release_year_dist = df1['release_year'].value_counts().sort_index(ascending=False).head(10)\n",
        "release_year_dist"
      ],
      "metadata": {
        "id": "QEoCRXUZLcpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize distribution of release years for the content\n",
        "# Define a color palette\n",
        "palette = sns.color_palette(\"colorblind\", len(release_year_dist))\n",
        "\n",
        "# Create a bar plot with missing values\n",
        "plt.figure(figsize=(10, 8))\n",
        "ax = sns.barplot(x=release_year_dist.index, y=release_year_dist.values, palette=palette)\n",
        "plt.title('Distribution of Release Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Number of shows/movies')\n",
        "\n",
        "# Adding the exact values on top of the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='baseline', fontsize=11, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qY9c1fpIaohG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "uqL6ZDBSuvNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create two columns\n",
        "tv_shows = df1[df1['type'] == 'TV Show']\n",
        "movies = df1[df1['type'] == 'Movie']"
      ],
      "metadata": {
        "id": "LqklC0HRExM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate distribution of movies release years\n",
        "movies_release_years = movies['release_year'].value_counts().sort_index(ascending=False).head(10)\n",
        "movies_release_years"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hE9_asl-t_ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize numner of movies release per year\n",
        "# Define colour palette\n",
        "palette = sns.color_palette(\"colorblind\", len(movies_release_years))\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10,8))\n",
        "ax=sns.barplot(x=movies_release_years.index, y=movies_release_years.values, palette=palette)\n",
        "plt.title('Number of movies release per year')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Number of movies')\n",
        "\n",
        "# adding the exact value on the top of the bar\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='baseline', fontsize=11, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kMe3f0tvuY4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate distribution of tv shows release years\n",
        "tv_shows_release_years = tv_shows['release_year'].value_counts().sort_index(ascending=False).head(10)\n",
        "tv_shows_release_years"
      ],
      "metadata": {
        "id": "EarnwyO9zfcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate distribution of tv shows release years\n",
        "# Define colour palette\n",
        "palette = sns.color_palette(\"colorblind\", len(tv_shows_release_years))\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10,8))\n",
        "ax=sns.barplot(x=tv_shows_release_years.index, y=tv_shows_release_years.values, palette=palette)\n",
        "plt.title('Number of TV shows release per year')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Number of TV shows')\n",
        "\n",
        "# adding the exact value on the top of the bar\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='baseline', fontsize=11, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nt4xFHSWzZXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In 2018, the number of both tv shows and movies are highest. In 2017 highest number of movies released and In 2020 highest number of tv shows released."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Release by month**"
      ],
      "metadata": {
        "id": "A_8fnBLZ6ptL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding columns of month and year of addition\n",
        "df1['month'] = pd.DatetimeIndex(df1['date_added']).month\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "4kVeeZF76pUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize release by month\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax=sns.countplot(x='month', data=df1, color='orange')\n",
        "plt.title('Release by Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of shows/movies')\n",
        "\n",
        "# show exact value on bar\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}', (p.get_x()+p.get_width()/2., p.get_height()),\n",
        "              ha='center', va='baseline', fontsize=11, color='black', xytext=(0, 5),\n",
        "              textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nimiBW6s75EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In 12th month means in December maximum number of content was added. From october to january highest number of content was added."
      ],
      "metadata": {
        "id": "gntraFsA9fKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure.figsize=(15, 6)\n",
        "sns.countplot(df1,  x=\"month\", hue=\"type\")\n",
        "plt.title('Release by Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of shows/movies')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HGX-ViSs93FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Top 10 countries who produce the most content?**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find out content by countries\n",
        "content_by_countries = df1['country'].value_counts().head(10)\n",
        "content_by_countries"
      ],
      "metadata": {
        "id": "wxFVI7dXax74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization of content by contries\n",
        "\n",
        "# Define a color palette\n",
        "palette = sns.color_palette(\"colorblind\", len(content_by_countries))\n",
        "\n",
        "# Create a bar plot with missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.barplot(x=content_by_countries.index, y=content_by_countries.values, palette=palette)\n",
        "plt.title('Content by Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Number of shows/movies')\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Adding the exact values on top of the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='baseline', fontsize=11, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find out tpo 10 contries in which maximum number of movies released\n",
        "top_10_countries_movies = movies['country'].value_counts().head(10)\n",
        "top_10_countries_movies"
      ],
      "metadata": {
        "id": "XjlJWNhQwX6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting top 10 contries in which most number of movies released\n",
        "# colour palette\n",
        "color_palette = sns.color_palette(\"husl\", len(top_10_countries_movies))\n",
        "\n",
        "# plot bar plot\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_10_countries_movies.index, y=top_10_countries_movies.values, palette=color_palette)\n",
        "plt.title('Top 10 Countries in which most number of movies released')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Number of movies')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nG_UoQVqwG-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_countries_tv_show = tv_shows['country'].value_counts().head(10)\n",
        "top_10_countries_tv_show\n",
        "\n",
        "# plot top 10 contries in which maximum number of tv shows released\n",
        "# colour palette\n",
        "color_palette = sns.color_palette(\"husl\", len(top_10_countries_movies))\n",
        "\n",
        "# plot bar plot\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_10_countries_tv_show.index, y=top_10_countries_tv_show.values, palette=color_palette)\n",
        "plt.title('Top 10 Countries in which most number of TV shows released')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Number of TV shows')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dG89Zkdvw1kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart, United states released more content that other contries."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# horizontal bar plot of top 10 contries content both tv shows and movies split\n",
        "country_order = df1['country'].value_counts()[:11].index\n",
        "content_data = df1.groupby('country')['type'].value_counts().unstack().loc[country_order]\n",
        "content_data['sum'] = content_data.sum(axis=1)\n",
        "content_data_ratio = (content_data.T/content_data['sum']).T[['Movie', 'TV Show']].sort_values(by='Movie', ascending=False)[::-1]\n",
        "\n",
        "#plot horizontal barplot\n",
        "plt.figure(figsize=(20, 10))\n",
        "content_data_ratio.plot(kind='barh',stacked=True, color=['red', 'black'])\n",
        "plt.title(\"tv shows and movies split\")\n",
        "plt.xlabel(\"Ratio\")\n",
        "plt.ylabel(\"Country\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sVQ6YAQ6y8VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Rating distribution of TV shows and Movies**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['rating']"
      ],
      "metadata": {
        "id": "yv_K1kDLcoCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign rating into gropued categories\n",
        "ratings = {\n",
        "    'TV-MA': 'Adults',\n",
        "    'R': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-14': 'Young Adults',\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'NR': 'Adults',\n",
        "    'TV-G': 'Kids',\n",
        "    'TV-Y': 'Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'NC-17': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'UR': 'Adults'\n",
        "}\n",
        "\n",
        "df1['target_ages'] = df1['rating'].replace(ratings)"
      ],
      "metadata": {
        "id": "_k894xNafOFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type should be categorical\n",
        "df1['type'] = df1['type'].astype('category')\n",
        "df1['target_ages'] = pd.Categorical(df1['target_ages'], categories = ['Kids', 'Teens', 'Young Adults', 'Adults', 'Older Kids'])"
      ],
      "metadata": {
        "id": "G1fH6veRh5Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "tOslU_vCiZYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create two columns\n",
        "tv_shows = df1[df1['type'] == 'TV Show']\n",
        "movies = df1[df1['type'] == 'Movie']"
      ],
      "metadata": {
        "id": "4is2N1LuilwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "rhmGcSHXi9CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rating based on rating system of all tv shows\n",
        "tv_shows['rating'].value_counts()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize rating distribution of all tv shows\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.pointplot(x=tv_shows['rating'].value_counts().index, y=tv_shows['rating'].value_counts().values, color='red')\n",
        "plt.title('Rating Distribution of TV Shows')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Number of TV Shows')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XhGRVBATjXt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize rating distribution of all movies\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.pointplot(x=movies['rating'].value_counts().index, y=movies['rating'].value_counts().values, color='red')\n",
        "plt.title('Rating Distribution of Movies')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Number of Movies')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9AULVBvVDJ-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a point plot to visualize the rating distribution of TV showa and movies because it effectively heighlights variablility within diffrent categories."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TV-MA has the highest number of ratings in both the cases i. e. tv shows as well as movies category."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "npegGcLyGVA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "ob1u-4HCHfoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **What are the most common genres on Netflix?**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find out top 10 genre of the movies\n",
        "top_10_genres = df1['listed_in'].value_counts().head(10)\n",
        "top_10_genres"
      ],
      "metadata": {
        "id": "1q1FKcYRQNcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization top 10 genre\n",
        "palette = sns.color_palette(\"colorblind\", len(top_10_genres))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(y='listed_in', data=df1, order=df1['listed_in'].value_counts().index[:10], palette=palette)\n",
        "plt.title('Top 10 Genres of shows/movies')\n",
        "plt.xlabel('Number of Shows/Movies')\n",
        "plt.ylabel('Genre')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing top 10 genres of tv_shows\n",
        "palette = sns.color_palette(\"colorblind\", len(top_10_genres))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(y='listed_in', data=tv_shows, order=tv_shows['listed_in'].value_counts().index[:10], palette=palette)\n",
        "plt.title('Top 10 Genres of shows/movies')\n",
        "plt.xlabel('Number of Shows/Movies')\n",
        "plt.ylabel('Genre')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PqDWg2arS150"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing top 10 genres of movies\n",
        "palette = sns.color_palette(\"colorblind\", len(top_10_genres))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(y='listed_in', data=movies, order=movies['listed_in'].value_counts().index[:10], palette=palette)\n",
        "plt.title('Top 10 Genres of shows/movies')\n",
        "plt.xlabel('Number of Shows/Movies')\n",
        "plt.ylabel('Genre')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vCA4A64oTPTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **How does the number of TV shows and movies vary by release year?**"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find out tv shows and movies vary by release year\n",
        "tv_shows_by_year = df1[df1['type'] == 'TV Show'].groupby('release_year').size()\n",
        "movies_by_year = df1[df1['type'] == 'Movie'].groupby('release_year').size()"
      ],
      "metadata": {
        "id": "aAD4EA1sVSS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize tv shows and movies vary by release year\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(tv_shows_by_year.index, tv_shows_by_year.values, label='TV Shows')\n",
        "plt.plot(movies_by_year.index, movies_by_year.values, label='Movies')\n",
        "plt.title('Number of TV Shows and Movies by Release Year')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Number of Shows/Movies')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OSFJc0k8VaMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph shows a significant increase in both TV shows and movies on Netflix starting from the 2000s, with a sharp spike in content around 2015-2019. TV shows have seen rapid growth, especially in the last decade, while the number of movies, after peaking, appears to have slightly declined recently."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix should continue investing in TV shows due to their rapid growth and strong engagement. Additionally, diversifying with more classic content could attract a broader audience. Monitoring the recent decline in movie additions can help maintain a balanced content library."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Duration**"
      ],
      "metadata": {
        "id": "vbOne--e0Gto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract numeric durations and convert to numeric type\n",
        "duration_numeric = movies['duration'].str.extract('(\\d+)').astype(float)\n",
        "duration_numeric"
      ],
      "metadata": {
        "id": "URib0S5X0GLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.distplot(duration_numeric, bins=20, kde=True, color='red', kde_kws={'color': 'black'})\n",
        "plt.title('Distribution of Movie Durations')\n",
        "plt.xlabel('Duration (minutes)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sL2jZrIo0bRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the distribution of TV SHOWS\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title(\"Distribution of TV Shows duration\",fontweight='bold')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Duration\")\n",
        "plt.ylabel(\"Count\")\n",
        "sns.countplot(x=tv_shows['duration'],data=tv_shows,order = tv_shows['duration'].value_counts().index)"
      ],
      "metadata": {
        "id": "MPj1FaoF7YSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above plot we can see that tv shows who have one season are more in number."
      ],
      "metadata": {
        "id": "t-KjMkAg_dZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Heatmap**"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'count' column exists\n",
        "df1['count'] = 1\n",
        "\n",
        "# Group by 'country' and sum the 'count' column, then sort\n",
        "data = df1.groupby('country')['count'].sum().sort_values(ascending=False).reset_index()[:10]\n",
        "\n",
        "# Extract top 10 countries\n",
        "top_countries = data['country']\n",
        "\n",
        "# Filter the dataframe for the top 10 countries\n",
        "df_heatmap = df1.loc[df1['country'].isin(top_countries)]\n",
        "\n",
        "# Create a crosstab of 'country' and 'target_ages' normalized by index\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'], df_heatmap['target_ages'], normalize=\"index\").T\n",
        "\n",
        "df_heatmap\n"
      ],
      "metadata": {
        "id": "qFMhBlAI5Exn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df_heatmap * 100, annot=True, cmap=\"plasma\", fmt=\".2f\", linewidths=.5, linecolor='gray',\n",
        "                     cbar_kws={'label': 'Percentage (%)'}, annot_kws={\"size\": 12})\n",
        "plt.title('Distribution of Target Ages by Country', fontweight=15)\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Target Ages')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SMFawH7325SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are five insights from the heatmap:\n",
        "\n",
        "1. **Young Adults in Spain and Mexico**:\n",
        "   - The highest percentage of content in Spain (83.58%) and Mexico (77.00%) is targeted at young adults.\n",
        "\n",
        "2. **Adults in France and Egypt**:\n",
        "   - France has a significant portion (67.83%) of content aimed at adults, followed by Egypt (27.72%).\n",
        "\n",
        "3. **Kids in Canada**:\n",
        "   - Canada has a notable percentage (18.08%) of content targeted at kids, which is higher compared to other countries.\n",
        "\n",
        "4. **Varied Target in India**:\n",
        "   - India has a diverse distribution of content across different age groups, with young adults (56.34%) and adults (25.57%) having significant shares.\n",
        "\n",
        "5. **Low Teen Content Across Countries**:\n",
        "   - The percentage of content targeted at teens is generally low across all countries, with the highest being in the United States (7.54%)."
      ],
      "metadata": {
        "id": "GVCWs2UE8II0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Hypothesis Testing**"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   **Null Hypothesis** : There is no diffrence between number of movies and tv shows. The praportion of movies are equal to or less than the praportion of tv shows.\n",
        "2.   **Alternate Hypothesis** : There is diffrence between number of movies and tv shows. The praportion of movies are greater than the praportion of tv shows.\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Counts from the pie chart data\n",
        "n_movies = 5372\n",
        "n_tvshows = 2398\n",
        "n_total = n_movies + n_tvshows\n",
        "\n",
        "# Perform the z-test for a single proportion\n",
        "stat, p_value = proportions_ztest(count=n_movies, nobs=n_total, value=0.5, alternative='two-sided')\n",
        "\n",
        "# Display the results\n",
        "print(f\"Z-statistic: {stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the number of movies and TV shows.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant evidence of a difference between the number of movies and TV shows.\")\n"
      ],
      "metadata": {
        "id": "T2UC5HosOPk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose z statistical test"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose Z test because I have large dataset."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   **Null Hypothesis** : Movies rated for kids and older kids are at least two hours long.\n",
        "\n",
        "2.   **Alternate Hypothesis** : Movies rated for kids and older kids are not at least two hours long.\n",
        "\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make copy of df1 dataset\n",
        "df1_hypo = df1.copy()\n",
        "df1_hypo.head()"
      ],
      "metadata": {
        "id": "mo8UMlaBSEiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter movies from \"type\" column\n",
        "df1_hypo = df1_hypo[df1_hypo['type'] == 'Movie']"
      ],
      "metadata": {
        "id": "5a2n9TqnSXdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign rating into gropued categories\n",
        "ratings_by_age = {\n",
        "    'TV-MA': 'Adults',\n",
        "    'R': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-14': 'Young Adults',\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'NR': 'Adults',\n",
        "    'TV-G': 'Kids',\n",
        "    'TV-Y': 'Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'NC-17': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'UR': 'Adults'\n",
        "}\n",
        "\n",
        "df1_hypo['target_ages'] = df1_hypo['rating'].replace(ratings_by_age)\n",
        "\n",
        "# unique target ages\n",
        "df1_hypo['target_ages'].unique()"
      ],
      "metadata": {
        "id": "wDwf5UDuShzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert target ages to categorical type with specified order\n",
        "df1_hypo['target_ages'] = pd.Categorical(df1_hypo['target_ages'], categories = ['Kids', 'Teens', 'Young Adults', 'Adults', 'Older Kids'])\n",
        "\n",
        "# extract numeric part from duration and converting to numeric type\n",
        "df1_hypo['duration_numeric'] = df1_hypo['duration'].str.extract('(\\d+)')\n",
        "df1_hypo['duration_numeric'] = pd.to_numeric(df1_hypo['duration_numeric'], errors='coerce')\n",
        "\n",
        "# display the first view\n",
        "df1_hypo.head()"
      ],
      "metadata": {
        "id": "xKkDLgK6Zd2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group by target ages and duration numeric and also find out mean\n",
        "group_by_ = df1_hypo[['target_ages','duration_numeric']].groupby(by='target_ages')\n",
        "group_by_\n",
        "\n",
        "#take mean\n",
        "group = group_by_.mean().reset_index()\n",
        "group"
      ],
      "metadata": {
        "id": "7eSxGbmxc1Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gruoping values in variables\n",
        "A = group_by_.get_group(\"Kids\")\n",
        "B = group_by_.get_group(\"Older Kids\")"
      ],
      "metadata": {
        "id": "CmBwTRQre-HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate mean and standard deviation\n",
        "mean_A = A['duration_numeric'].mean()\n",
        "std_A = A['duration_numeric'].std()\n",
        "mean_B = B['duration_numeric'].mean()\n",
        "std_B = B['duration_numeric'].std()"
      ],
      "metadata": {
        "id": "JPVtsLtHhjCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the result\n",
        "print(\"Mean of group A:\", mean_A)\n",
        "print(\"Standard Deviation of group A:\", std_A)\n",
        "print(\"Mean of group B:\", mean_B)\n",
        "print(\"Standard Deviation of group B:\", std_B)"
      ],
      "metadata": {
        "id": "HiHF026Hhwcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# length of A and B\n",
        "len_A = len(A)\n",
        "len_B = len(B)\n",
        "\n",
        "#print\n",
        "print(f'len_A = {len_A}, len_B = {len_B}')"
      ],
      "metadata": {
        "id": "lK84X0DmiInx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# degree of freedom\n",
        "DOF = len_A + len_B - 2\n",
        "\n",
        "#print\n",
        "print(f'DOF = {DOF}')"
      ],
      "metadata": {
        "id": "YILiRCDajmUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pooled std\n",
        "pooled_std = ((len_B)*(std_B)**2 + (len_A)*(std_A)**2)/DOF\n",
        "sp = np.sqrt(pooled_std)\n",
        "\n",
        "#print\n",
        "print(f'sp = {sp}')"
      ],
      "metadata": {
        "id": "Lq6ymiSAkSsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t_value\n",
        "t_value = (mean_A - mean_B)/(sp*np.sqrt(1/len_A + 1/len_B))\n",
        "\n",
        "#print\n",
        "print(f't_value = {t_value}')"
      ],
      "metadata": {
        "id": "KAbzdmq6k5Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform t test\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "t_statistic, p_value = ttest_ind(A['duration_numeric'], B['duration_numeric'])\n",
        "\n",
        "#print\n",
        "print(f't_statistic = {t_statistic}')\n",
        "print(f'p_value = {p_value}')"
      ],
      "metadata": {
        "id": "JDAJ-An7lA3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   The t_statistic value indcates that the mean is less than 120 min and negative sign suggest that the mean duration of movies for kids and older kids is less than 120 min.\n",
        "2.  P_value is also very small.\n",
        "3. From above 2 values we can reject null hypothesis.\n",
        "\n"
      ],
      "metadata": {
        "id": "SJjk8PTYmUFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis** : The duration which is more than 90 mins are movies.\n",
        "\n",
        "**Alternate Hypothesis** : The duration which is more than 90 mins are NOT movies."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# creating binary vatiabales\n",
        "df1_hypo['duration_binary'] = np.where(df1_hypo['duration_numeric'] > 90, 1, 0)\n",
        "\n",
        "# observed proportion of duration > 90 min\n",
        "observed_prop = df1_hypo['duration_binary'].mean()\n",
        "print(f'observed_prop = {observed_prop}')"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform praportion test\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "n = len(df1_hypo)\n",
        "baseline_prop = 0.5\n",
        "stat, p_value = proportions_ztest(count=n*observed_prop, nobs=n, value=baseline_prop, alternative='larger')\n",
        "\n",
        "#print result\n",
        "print(f\"Z-statistic: {stat}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "IydHffFAol8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.dtypes"
      ],
      "metadata": {
        "id": "xjE2w6CzDPc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "RR7CDJEDDXOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['description'].astype(str)"
      ],
      "metadata": {
        "id": "0dWbd2w4MjoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making list of description feature\n",
        "df1['description'] = df1['description'].apply(lambda x: x.split(' '))"
      ],
      "metadata": {
        "id": "iDDkdzyYblWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert text feature to string from list\n",
        "df1['description'] = df1['description'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "7yDiwsvpb-xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing all the words in the text features\n",
        "df1['description'] = df1['description'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "def remove_punctuations(text):\n",
        "  import string\n",
        "  for punctuation in string.punctuation:\n",
        "    text = text.replace(punctuation, '')\n",
        "  return text"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply above function\n",
        "df1['description'] = df1['description'].apply(remove_punctuations)"
      ],
      "metadata": {
        "id": "5sdjRO9Tehkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['description'][0:10]"
      ],
      "metadata": {
        "id": "hVNJ_A2QemJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using nltk library download stopwords\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "# define stopwords\n",
        "def stopwords(text):\n",
        "  text = [word for word in text.split() if word not in sw]\n",
        "  return \" \".join(text)"
      ],
      "metadata": {
        "id": "8SVHPcOafM8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply above function\n",
        "df1['description'] = df1['description'].apply(stopwords)"
      ],
      "metadata": {
        "id": "qn61K9fRfmQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['description'][0:10]"
      ],
      "metadata": {
        "id": "RPfUbntpfq_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import TfidVectorizer from sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "xhQ7EP5sgNdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tkinter.constants import X\n",
        "# apply\n",
        "tf = TfidfVectorizer(max_features = 5000)\n",
        "X = tf.fit_transform(df1['description'])"
      ],
      "metadata": {
        "id": "T8NdMKXHgfWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "1WeT2Mq0g24Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert X to array\n",
        "X = X.toarray()"
      ],
      "metadata": {
        "id": "iMwCP9QAhGpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 : KMeans Clustering"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import library\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#initializing the list for the values of wcss\n",
        "wcss = []\n",
        "\n",
        "# using for loop for intrations from 1 to 30\n",
        "for i in range(1,30):\n",
        "  kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "  kmeans.fit(X)\n",
        "  wcss.append(kmeans.inertia_)\n",
        "\n",
        "# plot results\n",
        "plt.plot(range(1,30), wcss)\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "sill = []\n",
        "\n",
        "for i in range(2, 30):\n",
        "  model = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "  model.fit(X)\n",
        "  labels = model.labels_\n",
        "  sill.append(silhouette_score(X, labels))\n",
        "  print(f'Silhouette score for {i} clusters: {sill[-1]}')"
      ],
      "metadata": {
        "id": "3Ge4WRe4jqFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the silhouette scores\n",
        "plt.plot(range(2, 30), sill, 'bs--')\n",
        "plt.xticks(range(2, 30))\n",
        "plt.grid()\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IdvH4GIsoF-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the k means model on a dataset\n",
        "kmeans = KMeans(n_clusters=26, init='k-means++', random_state=42)\n",
        "y_kmeans = kmeans.fit_predict(X)"
      ],
      "metadata": {
        "id": "YmxWn1KqqvsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the clusters and evalute the silhouette score\n",
        "score = silhouette_score(X, y_kmeans)\n",
        "print(f'Silhouette score: {score}')"
      ],
      "metadata": {
        "id": "6LQsIthhxSY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# davies bouldin score of our clusters\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "davies_bouldin_score(X, y_kmeans)"
      ],
      "metadata": {
        "id": "K0xiMsQ-xmBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a seperate column for the cluster\n",
        "df1['cluster'] = y_kmeans"
      ],
      "metadata": {
        "id": "trLbLPZ-xu_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['cluster'].value_counts()"
      ],
      "metadata": {
        "id": "TTnL5HXix6tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the graph\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.countplot(x='cluster', data=df1, ax=ax, hue='type')\n",
        "ax.set_title('Cluster Distribution')\n",
        "ax.set_xlabel('Cluster')\n",
        "ax.set_ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pVI0jdTHyG0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cluster 7 has the heighest number of datapoints"
      ],
      "metadata": {
        "id": "yp4VbDpVyaay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot for clusters\n",
        "fig = px.scatter(df1, y=\"description\", x=\"cluster\", color=\"cluster\")\n",
        "fig.update_traces(marker_size = 100)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "HDLk_CAIyg6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 : Hierarchy Cluster"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import library\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "# plot dendogram\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Customer Dendograms\")\n",
        "dend = shc.dendrogram(shc.linkage(X, method='ward'))"
      ],
      "metadata": {
        "id": "DTAkQeJHzIf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Agglomerative Clustering**"
      ],
      "metadata": {
        "id": "d5MXgdj0znuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import library\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# training the model\n",
        "model = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
        "y_pred = model.fit_predict(X)"
      ],
      "metadata": {
        "id": "YbTH7yqvzmSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hc = df1.copy()\n",
        "\n",
        "# create a seperate column where each row is assigned to their separate cluster\n",
        "df_hc['cluster'] = y_pred\n",
        "df_hc.head()"
      ],
      "metadata": {
        "id": "Iqbx0a7a1Qrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation**"
      ],
      "metadata": {
        "id": "3hHltZQl11c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sillhoute coefficient\n",
        "score = silhouette_score(X, y_pred)\n",
        "print(f'Silhouette score: {score}')"
      ],
      "metadata": {
        "id": "tx7cRVbm11JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# davies bouldin score\n",
        "davies_bouldin_score(X, y_pred)"
      ],
      "metadata": {
        "id": "8TOK3dL_zjKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}